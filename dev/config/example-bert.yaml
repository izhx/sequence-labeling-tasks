data:
  cache: srl-en-bert
  data_dir: ./UniversalPropositions/UP_English-EWT/
  lang: en
  name: srl
  pretrained_fields: [words]
  read_test: true
model:
  dropout: 0.33
  encoder: {hidden_size: 400, name: bilstm, num_layers: 3}
  indicator_dim: 100
  name: srl
  pos_dim: 100
  transform_dim: 300
  word_embedding: 
    layer_num: 12
    name_or_path: YOUR_BERT_PATH/bert-base-cased/
    scalar_mix: 
      do_layer_norm: true
optim: 
  lr: 0.001
  name: Adam
trainer: 
  batch_size: 64
  early_stop: true
  epoch_num: 200
  epoch_start: 0
  log_dir: YOUR_LOG_PATH/,
  prefix: en-bert
  save_after: 10
  save_dir: ./dev/model/
  save_strategy: best
  tensorboard: false
vocab:
  min_count: 
    words: 1
  pretrained_files: 
    words: ./dev/vec/glove_6B_300d_UP.vec
